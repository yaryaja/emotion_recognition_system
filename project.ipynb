{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import scipy.signal\n",
    "\n",
    "from scipy.signal import lfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Data Labelling and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "'''\n",
    "LABELS :-\n",
    " 0 - ANGER\n",
    " 1 - BORED\n",
    " 2 - DISGUST\n",
    " 3 - ANXIETY\n",
    " 4 - HAPPY\n",
    " 5 - SAD\n",
    " 6 - Neutral\n",
    "\n",
    "GENDER :-\n",
    "  1 - MALE\n",
    "  0 - FEMALE\n",
    "'''\n",
    "\n",
    "labels_encoded = {'W':0, 'L':1, 'E':2, 'A':3, 'F':4, 'T':5, 'N':6}\n",
    "gender_encoded = {'03':1 , '10' : 1, '11':1 , '12':1 , '15':1, '08':0, '09':0, '13':0 , '14':0, '16':0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "file_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavefilePath=\"./wav\"\n",
    "for file_name in os.listdir(wavefilePath):\n",
    "  if file_name.endswith('.wav'):\n",
    "    file_paths.append(file_name)\n",
    "    labels.append(labels_encoded[file_name[5]])\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'file_path':file_paths,\n",
    "        'label':labels,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Feature Extraction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio load function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav(wav):\n",
    "    y, sr = sf.read(wav)\n",
    "    return y,sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-padded signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_signal(win_len, win_hop, y, size):\n",
    "        \n",
    "    num_frames = (size - win_len) // win_hop + 1   # Calculate the number of frames without padding\n",
    "    \n",
    "    padding_samples = max(0, (num_frames - 1) * win_hop + win_len - size)   # Calculate the number of samples needed for padding\n",
    "    padded_signal = np.pad(y, (0, padding_samples), mode='constant')  # Zero pad the signal     \n",
    "    num_frames_padded = (size + padding_samples - win_len) // win_hop + 1  # Recalculate the number of frames after padding\n",
    "    \n",
    "    return padded_signal, num_frames_padded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-th frame of signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nth_frame(n, win_len, win_hop, y): # n >= 0\n",
    "    x = np.zeros(win_len)\n",
    "\n",
    "    for i in range(0,win_len):\n",
    "        x[i] = y[(win_hop * n) + i] # y is the zero-padded signal\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing &beta; parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) For one frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta(y, sr, fl, fh, fm):\n",
    "    fft_fr = np.abs(np.fft.fft(y))\n",
    "    # fft_fr = 20 * np.log10(fft_fr)\n",
    "    freq = np.fft.fftfreq(len(fft_fr), 1/sr)\n",
    "\n",
    "    n = len(freq)\n",
    "    sum_l = 0\n",
    "    sum_h = 0\n",
    "\n",
    "    for i in range(0,n):\n",
    "        if 0 <= freq[i] <= fl:\n",
    "            sum_l = sum_l + (fft_fr[i]*fft_fr[i])\n",
    "\n",
    "    for i in range(0,n):\n",
    "        if fh <= freq[i] <= fm:\n",
    "            sum_h = sum_h + (fft_fr[i]*fft_fr[i])\n",
    "\n",
    "    return sum_h/sum_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) For entire signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_arr(y, sr, fl, fh, fm, win_len, win_hop, frames):\n",
    "    \n",
    "    b = np.zeros(frames)\n",
    "\n",
    "    for i in range(0,frames):\n",
    "        x = nth_frame(i, win_len, win_hop, y)\n",
    "        b[i] = beta(x, sr, fl, fh, fm)\n",
    "\n",
    "    # b_mean = sum(b)/len(b)\n",
    "    b_mean = np.mean(b)\n",
    "    b_std_dev = np.std(b)\n",
    "    \n",
    "    return b, b_mean, b_std_dev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZFF signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zff(y, sr, fr_len):\n",
    "    size = len(y)\n",
    "    x = np.zeros(size)\n",
    "\n",
    "\n",
    "    for i in range(0,size):\n",
    "        x[i] = y[i] - y[i-1]\n",
    "    \n",
    "\n",
    "    b = [1]\n",
    "    a = [1, -2, 1]\n",
    "\n",
    "    y1 = lfilter(b, a, x)\n",
    "    y2 = lfilter(b, a, y1)\n",
    "\n",
    "    N = int(((int)((sr*fr_len)/1000) - 1)/2)\n",
    "    n = len(y2)\n",
    "    y = np.zeros(n)\n",
    "\n",
    "    x_nm = np.sum(y2[:2 * N + 1])\n",
    "\n",
    "    for i in range(N+1, n):\n",
    "        if i + N+1 > n-1:\n",
    "            y[i] = y[i - 1]\n",
    "        else:\n",
    "            y[i] = y2[i] - (x_nm / (2*N + 1))\n",
    "            x_nm = x_nm - y2[i - N] + y2[i + (N+1)]\n",
    "\n",
    "\n",
    "    x_nm = np.sum(y[:2 * N + 1])\n",
    "\n",
    "    y0 = np.zeros(n)\n",
    "\n",
    "    for i in range(N+1, n):\n",
    "        if i + N+1 > n-1:\n",
    "            y0[i] = y0[i - 1]\n",
    "        else:\n",
    "            y0[i] = y[i] - (x_nm / (2*N + 1))\n",
    "            x_nm = x_nm - y[i - N] + y[i + (N+1)]\n",
    "\n",
    "\n",
    "    y0 /= np.max(y0)\n",
    "\n",
    "    return y0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $F_0$ calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch(y, sr, fr_len):\n",
    "\n",
    "    z = zff(y,sr,fr_len)\n",
    "    t = np.arange(0,len(z))/sr\n",
    "    n = len(z)\n",
    "\n",
    "    A = []\n",
    "\n",
    "    for i in range(0,n):\n",
    "\n",
    "        if z[i] == 0 and 0 <= i <= n-2:\n",
    "            if z[i-1] < z[i] < z[i+1]:\n",
    "                A.append(t[i])\n",
    "        \n",
    "        else:\n",
    "            if i <= n-2 and z[i+1] > 0 and z[i] < 0:\n",
    "                x = (t[i] + t[i+1])/2\n",
    "                A.append(x)\n",
    "\n",
    "    n = len(A) - 1\n",
    "\n",
    "    B = np.zeros(n)\n",
    "\n",
    "    for i in range(0,n):\n",
    "        B[i] = A[i+1] - A[i]\n",
    "        B[i] = 1/B[i]\n",
    "\n",
    "    b_mean = np.mean(B)\n",
    "    b_std_dev = np.std(B)\n",
    "    \n",
    "    return B, b_mean, b_std_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SoE calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(x1, x2, y1, y2):\n",
    "    return (y2-y1)/(x2-x1)\n",
    "\n",
    "def SoE(y, sr, fr_len):\n",
    "\n",
    "    z = zff(y,sr,fr_len)\n",
    "    t = np.arange(0,len(z))/sr\n",
    "    n = len(z)\n",
    "\n",
    "    A = []\n",
    "\n",
    "    for i in range(0,n):\n",
    "\n",
    "        if z[i] == 0 and 0 <= i <= n-2:\n",
    "            if z[i-1] < z[i] < z[i+1]:\n",
    "                s = slope(t[i-1],t[i+1],z[i-1],z[i+1])\n",
    "                A.append(s)\n",
    "        \n",
    "        else:\n",
    "            if i <= n-2 and z[i+1] > 0 and z[i] < 0:\n",
    "                s = slope(t[i],t[i+1],z[i],z[i+1])\n",
    "                A.append(s)\n",
    "\n",
    "    a_mean = np.mean(A)\n",
    "    a_std_dev = np.std(A)\n",
    "\n",
    "    \n",
    "    return A, a_mean, a_std_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCI extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gci(x):\n",
    "\n",
    "    # Compute the first derivative of the speech signal\n",
    "    speech_derivative = np.diff(x)\n",
    "\n",
    "    # Identify zero-crossings in the derivative signal\n",
    "    zero_crossings = np.where(np.diff(np.sign(speech_derivative)))[0]\n",
    "\n",
    "    # Filter zero-crossings based on amplitude and spacing criteria\n",
    "    gci_candidates = [zc for zc in zero_crossings if np.abs(speech_derivative[zc]) > 0.01]\n",
    "\n",
    "    return gci_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hilbert envelope extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hilbert_env(x,sr,frame_length,frame_shift,order_lp):\n",
    "    # LP analysis\n",
    "    frames = librosa.effects.split(x, top_db=30, frame_length=int(frame_length * 0.001 * sr), hop_length=int(frame_shift * 0.001 * sr))\n",
    "    lp_residuals = []\n",
    "\n",
    "    for frame in frames:\n",
    "        if(frame[1] > frame[0]):\n",
    "            # LP analysis\n",
    "            coefficients = librosa.lpc(x[frame[0]:frame[1]], order = order_lp)\n",
    "            \n",
    "            # LP residual\n",
    "            lp_residual = np.convolve(coefficients, x[frame[0]:frame[1]], mode='full')[:len(x[frame[0]:frame[1]])]\n",
    "            lp_residuals.append(lp_residual)\n",
    "\n",
    "    if(len(lp_residuals) != 0):\n",
    "        lp_residuals = np.concatenate(lp_residuals)\n",
    "\n",
    "        # Hilbert envelope\n",
    "        hilbert_envelope = np.abs(scipy.signal.hilbert(lp_residuals))\n",
    "\n",
    "        return hilbert_envelope\n",
    "    \n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EoE extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EoE(x,sr,frame_length,frame_shift,order_lp):\n",
    "    gci_x = gci(x)\n",
    "    gci_len = len(gci_x)\n",
    "\n",
    "    EoE_arr = []\n",
    "\n",
    "    for i in range(1,gci_len):\n",
    "        y = x[gci_x[i]-22 : gci_x[i]+22]\n",
    "        y1 = hilbert_env(y,sr,frame_length,frame_shift,order_lp)\n",
    "        \n",
    "        if(len(y1) != 0):\n",
    "            EoE_arr.append(sum(y1**2))\n",
    "\n",
    "    a_mean = np.mean(EoE_arr)\n",
    "    a_std_dev = np.std(EoE_arr)\n",
    "    \n",
    "    return EoE_arr, a_mean, a_std_dev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# C) Training and Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_len = 512\n",
    "win_hop = 256\n",
    "\n",
    "fl = 550\n",
    "fh = 800\n",
    "fm = 4000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_len = 10 # in milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pitch feature extraction\n",
    "\n",
    "pitch_list = []\n",
    "pitch_label = []\n",
    "\n",
    "x=1\n",
    "for file in df['file_path']:\n",
    "    y1,sr=librosa.load(f'./wav/{file}')\n",
    "    size1 = np.size(y1)\n",
    "    x1, frames1 = pad_signal(win_len, win_hop, y1, size1)\n",
    "    b1, m1, sd1 = pitch(x1, sr, fr_len)\n",
    "    pitch_list.append(b1)\n",
    "    pitch_label.append(labels_encoded[file[5]])\n",
    "\n",
    "# audio_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the arrays:\n",
    "\n",
    "len_pitch_list = len(pitch_list)\n",
    "max_len_pl = -1\n",
    "for i in range(0,len_pitch_list):\n",
    "    max_len_pl = max(max_len_pl, len(pitch_list[i]))\n",
    "\n",
    "\n",
    "max_length = max(len(arr) for arr in pitch_list)\n",
    "\n",
    "\n",
    "for i in range(len(pitch_list)):\n",
    "    current_length = len(pitch_list[i])\n",
    "    if current_length < max_length:\n",
    "        pitch_list[i] = np.concatenate((pitch_list[i], np.zeros(max_length - current_length)))\n",
    "    pitch_list[i] = np.nan_to_num(pitch_list[i], nan=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5462962962962963"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X1 = pitch_list\n",
    "Y1 = pitch_label\n",
    "X_train1, X_test1, Y_train1, Y_test1 = train_test_split(X1,Y1,test_size=0.2)\n",
    "\n",
    "np.random.seed(10)\n",
    "model=RandomForestClassifier()\n",
    "model.fit(X_train1,Y_train1)\n",
    "model.score(X_test1,Y_test1)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14048\\1677377293.py:18: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return sum_h/sum_l\n"
     ]
    }
   ],
   "source": [
    "#Loudness feature extraction\n",
    "\n",
    "beta_list = []\n",
    "beta_label = []\n",
    "\n",
    "x=1\n",
    "for file in df['file_path']:\n",
    "    y2,sr=librosa.load(f'./wav/{file}')\n",
    "    size2 = np.size(y2)\n",
    "    x2, frames2 = pad_signal(win_len, win_hop, y2, size2)\n",
    "    b2, m2, sd2 = beta_arr(x2, sr, fl, fh, fm, win_len, win_hop, int(frames2))\n",
    "    beta_list.append(b2)\n",
    "    beta_label.append(labels_encoded[file[5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the arrays:\n",
    "\n",
    "len_beta_list = len(beta_list)\n",
    "max_len_bl = -1\n",
    "for i in range(0,len_beta_list):\n",
    "    max_len_bl = max(max_len_bl, len(beta_list[i]))\n",
    "\n",
    "\n",
    "max_length = max(len(arr) for arr in beta_list)\n",
    "\n",
    "\n",
    "for i in range(len(beta_list)):\n",
    "    current_length = len(beta_list[i])\n",
    "    if current_length < max_length:\n",
    "        beta_list[i] = np.concatenate((beta_list[i], np.zeros(max_length - current_length)))\n",
    "    beta_list[i] = np.nan_to_num(beta_list[i], nan=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46296296296296297"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = beta_list\n",
    "Y2 = beta_label\n",
    "X_train2, X_test2, Y_train2, Y_test2=train_test_split(X2,Y2,test_size=0.2)\n",
    "\n",
    "np.random.seed(10)\n",
    "model=RandomForestClassifier()\n",
    "model.fit(X_train2,Y_train2)\n",
    "model.score(X_test2,Y_test2)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SoE feature extraction\n",
    "\n",
    "SoE_list = []\n",
    "SoE_label = []\n",
    "\n",
    "x=1\n",
    "for file in df['file_path']:\n",
    "    y3,sr=librosa.load(f'./wav/{file}')\n",
    "    size3 = np.size(y3)\n",
    "    x3, frames3 = pad_signal(win_len, win_hop, y3, size3)\n",
    "    b3, m3, sd3 = SoE(x3, sr, fr_len)\n",
    "    \n",
    "    SoE_list.append(b3)\n",
    "    SoE_label.append(labels_encoded[file[5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the arrays:\n",
    "\n",
    "len_SoE_list = len(SoE_list)\n",
    "max_len_sl = -1\n",
    "for i in range(0,len_SoE_list):\n",
    "    max_len_sl = max(max_len_sl, len(SoE_list[i]))\n",
    "\n",
    "\n",
    "max_length = max(len(arr) for arr in SoE_list)\n",
    "\n",
    "\n",
    "for i in range(len(SoE_list)):\n",
    "    current_length = len(SoE_list[i])\n",
    "    if current_length < max_length:\n",
    "        SoE_list[i] = np.concatenate((SoE_list[i], np.zeros(max_length - current_length)))\n",
    "    SoE_list[i] = np.nan_to_num(SoE_list[i], nan=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42592592592592593"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3 = SoE_list\n",
    "Y3 = SoE_label\n",
    "X_train3, X_test3, Y_train3, Y_test3 = train_test_split(X3,Y3,test_size=0.2)\n",
    "\n",
    "np.random.seed(10)\n",
    "model=RandomForestClassifier()\n",
    "model.fit(X_train3,Y_train3)\n",
    "model.score(X_test3,Y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EoE feature extraction\n",
    "\n",
    "order_lp = 10\n",
    "frame_length = 16  # in milliseconds\n",
    "frame_shift = 2    # in milliseconds\n",
    "region_around_gci = 2  # in milliseconds\n",
    "\n",
    "EoE_list = []\n",
    "EoE_label = []\n",
    "\n",
    "x=1\n",
    "cnt = 0\n",
    "for file in df['file_path']:\n",
    "        \n",
    "        y4,sr=librosa.load(f'./wav/{file}')\n",
    "        size4 = np.size(y4)\n",
    "        x4, frames4 = pad_signal(win_len, win_hop, y4, size4)\n",
    "        b4, m4, sd4 = EoE(x4,sr,frame_length,frame_shift,order_lp)\n",
    "        \n",
    "        EoE_list.append(b4)\n",
    "        EoE_label.append(labels_encoded[file[5]])\n",
    "\n",
    "# len(EoE_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding the arrays:\n",
    "\n",
    "len_EoE_list = len(EoE_list)\n",
    "max_len_el = -1\n",
    "for i in range(0,len_EoE_list):\n",
    "    max_len_el = max(max_len_el, len(EoE_list[i]))\n",
    "\n",
    "\n",
    "max_length = max(len(arr) for arr in EoE_list)\n",
    "\n",
    "\n",
    "for i in range(len(EoE_list)):\n",
    "    current_length = len(EoE_list[i])\n",
    "    if current_length < max_length:\n",
    "        EoE_list[i] = np.concatenate((EoE_list[i], np.zeros(max_length - current_length)))\n",
    "    EoE_list[i] = np.nan_to_num(EoE_list[i], nan=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4 = EoE_list\n",
    "Y4 = EoE_label\n",
    "X_train4, X_test4, Y_train4, Y_test4 = train_test_split(X4,Y4,test_size=0.2)\n",
    "\n",
    "np.random.seed(10)\n",
    "model=RandomForestClassifier()\n",
    "model.fit(X_train4,Y_train4)\n",
    "model.score(X_test4,Y_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44755244755244755"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training for pitch and loudness together\n",
    "\n",
    "pitch_beta_list = []\n",
    "\n",
    "for i in range(len_pitch_list):\n",
    "    pitch_beta_list.append(np.concatenate((pitch_list[i], beta_list[i])))\n",
    "\n",
    "X12 = pitch_beta_list\n",
    "Y12 = SoE_label\n",
    "X_train12, X_test12, Y_train12, Y_test12 = train_test_split(X12,Y12,test_size=0.2)\n",
    "\n",
    "np.random.seed(10)\n",
    "model=RandomForestClassifier()\n",
    "model.fit(X_train12,Y_train12)\n",
    "model.score(X_test12,Y_test12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4537037037037037"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training for pitch and SoE together\n",
    "\n",
    "pitch_SoE_list = []\n",
    "\n",
    "for i in range(len_pitch_list):\n",
    "    pitch_SoE_list.append(np.concatenate((pitch_list[i], SoE_list[i])))\n",
    "\n",
    "X13 = pitch_SoE_list\n",
    "Y13 = SoE_label\n",
    "X_train13, X_test13, Y_train13, Y_test13 = train_test_split(X13,Y13,test_size=0.2)\n",
    "\n",
    "np.random.seed(10)\n",
    "model=RandomForestClassifier()\n",
    "model.fit(X_train13,Y_train13)\n",
    "model.score(X_test13,Y_test13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49074074074074076"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training for loudness and SoE together\n",
    "\n",
    "beta_SoE_list = []\n",
    "\n",
    "for i in range(len_pitch_list):\n",
    "    beta_SoE_list.append(np.concatenate((beta_list[i], SoE_list[i])))\n",
    "\n",
    "X23 = beta_SoE_list\n",
    "Y23 = SoE_label\n",
    "X_train23, X_test23, Y_train23, Y_test23 = train_test_split(X23,Y23,test_size=0.2)\n",
    "\n",
    "np.random.seed(10)\n",
    "model=RandomForestClassifier()\n",
    "model.fit(X_train23,Y_train23)\n",
    "model.score(X_test23,Y_test23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4166666666666667"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training for loudness and EoE together\n",
    "\n",
    "beta_EoE_list = []\n",
    "\n",
    "for i in range(len_pitch_list):\n",
    "    beta_EoE_list.append(np.concatenate((beta_list[i], EoE_list[i])))\n",
    "\n",
    "X24 = beta_EoE_list\n",
    "Y24 = SoE_label\n",
    "X_train24, X_test24, Y_train24, Y_test24 = train_test_split(X24,Y24,test_size=0.2)\n",
    "\n",
    "np.random.seed(15)\n",
    "model=RandomForestClassifier()\n",
    "model.fit(X_train24,Y_train24)\n",
    "model.score(X_test24,Y_test24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5370370370370371"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training for three features: pitch, beta and SoE together\n",
    "\n",
    "full_list1 = []\n",
    "\n",
    "\n",
    "for i in range(len_pitch_list):\n",
    "    full_list1.append(np.concatenate((pitch_list[i], np.concatenate((beta_list[i], SoE_list[i])))))\n",
    "\n",
    "X123 = full_list1\n",
    "Y123 = SoE_label\n",
    "X_train123, X_test123, Y_train123, Y_test123 = train_test_split(X123,Y123,test_size=0.2)\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "model=RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train123,Y_train123)\n",
    "model.score(X_test123,Y_test123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4537037037037037"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training for three features: pitch, beta and EoE together\n",
    "\n",
    "full_list2 = []\n",
    "\n",
    "\n",
    "for i in range(len_pitch_list):\n",
    "    full_list2.append(np.concatenate((pitch_list[i], np.concatenate((beta_list[i], EoE_list[i])))))\n",
    "\n",
    "X124 = full_list2\n",
    "Y124 = SoE_label\n",
    "X_train124, X_test124, Y_train124, Y_test124 = train_test_split(X124,Y124,test_size=0.2)\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "model=RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train124,Y_train124)\n",
    "model.score(X_test124,Y_test124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4351851851851852"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training for three features: pitch, SoE and EoE together\n",
    "\n",
    "full_list3 = []\n",
    "\n",
    "\n",
    "for i in range(len_pitch_list):\n",
    "    full_list3.append(np.concatenate((pitch_list[i], np.concatenate((SoE_list[i], EoE_list[i])))))\n",
    "\n",
    "X134 = full_list3\n",
    "Y134 = SoE_label\n",
    "X_train134, X_test134, Y_train134, Y_test134 = train_test_split(X134,Y134,test_size=0.2)\n",
    "\n",
    "np.random.seed(15)\n",
    "\n",
    "model=RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train134,Y_train134)\n",
    "model.score(X_test134,Y_test134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5185185185185185"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training for all features\n",
    "\n",
    "full_list4 = []\n",
    "\n",
    "\n",
    "for i in range(len_pitch_list):\n",
    "    full_list4.append(np.concatenate((pitch_list[i], np.concatenate((beta_list[i], np.concatenate((SoE_list[i], EoE_list[i])))))))\n",
    "\n",
    "X1234 = full_list4\n",
    "Y1234 = SoE_label\n",
    "X_train1234, X_test1234, Y_train1234, Y_test1234 = train_test_split(X1234,Y1234,test_size=0.2)\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "model=RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train1234,Y_train1234)\n",
    "model.score(X_test1234,Y_test1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.070886329595765"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Parameters\n",
    "# order_lp = 10\n",
    "# frame_length = 16  # in milliseconds\n",
    "# frame_shift = 2    # in milliseconds\n",
    "# region_around_gci = 2  # in milliseconds\n",
    "\n",
    "# x_load, sr = sf.read(\"03a01Fa.wav\")\n",
    "# ans, b, m = EoE(x_load,sr,frame_length,frame_shift,order_lp)\n",
    "# np.max(ans)\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5185185185185185\n"
     ]
    }
   ],
   "source": [
    "# z = model.predict(X_test1234)\n",
    "# # print(z)\n",
    "\n",
    "# # len(X_test1234)\n",
    "\n",
    "# print(accuracy_score(Y_test1234, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
